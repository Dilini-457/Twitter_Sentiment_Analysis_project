{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7184\\2053990845.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mmatplotlib\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mstyle\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mstyle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'ggplot'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtextblob\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTextBlob\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mnltk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenize\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mword_tokenize\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mnltk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstem\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPorterStemmer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"vaccination_tweets.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preview Dataset and more information about the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset.shape\n",
    "dataset.head()\n",
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#null values in the dataset\n",
    "dataset.isnull().sum()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#creating a data set which is only consisting with text data\n",
    "#all column names\n",
    "dataset.columns\n",
    "text_dataset = dataset.drop([], axis=1)\n",
    "text_dataset.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(text_dataset['text'].iloc[0], \"\\n\")\n",
    "print(text_dataset['text'].iloc[1], \"\\n\")\n",
    "print(text_dataset['text'].iloc[2], \"\\n\")\n",
    "print(text_dataset['text'].iloc[3], \"\\n\")\n",
    "print(text_dataset['text'].iloc[4], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Text Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text_dataset.info()\n",
    "\n",
    "\n",
    "def data_processing(text):\n",
    "    #process lowercase\n",
    "    text = text.lower()\n",
    "    #remove url in tweets\n",
    "    text = re.sub(r\"https\\S+|www\\S+https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    #remove punctuation\n",
    "    text = re.sub(r'\\@w+|\\#', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text_tokens = word_tokenize(text)\n",
    "    filtered_text = [w for w in text_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Add Preprocessing function\n",
    "text_dataset.text = text_dataset['text'].apply(data_processing)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Remove Duplicates\n",
    "text_dataset = text_dataset.drop_duplicates('text')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stemming"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def stemming(data):\n",
    "    text = [stemmer.stem(word) for word in data]\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Apply stemming inti process data\n",
    "text_dataset['text'] = text_dataset['text'].apply(lambda x: stemming(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Display process data\n",
    "text_dataset.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#check the effects of the preprocessing\n",
    "print(text_dataset['text'].iloc[0], \"\\n\")\n",
    "print(text_dataset['text'].iloc[1], \"\\n\")\n",
    "print(text_dataset['text'].iloc[2], \"\\n\")\n",
    "print(text_dataset['text'].iloc[3], \"\\n\")\n",
    "print(text_dataset['text'].iloc[4], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#to see the updated no of columns\n",
    "text_dataset.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#calculate the polarity of the sentences\n",
    "def polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#add the calculated polarity into dataframe\n",
    "text_dataset['polarity'] = text_dataset['text'].apply(polarity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text_dataset.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Add sentiment column to the data frame\n",
    "def sentiment(label):\n",
    "    if label < 0:\n",
    "        return \"Negative\"\n",
    "    elif label == 0:\n",
    "        return \"Neutral\"\n",
    "    elif label > 0:\n",
    "        return \"Positive\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Add the function ito data frame\n",
    "text_dataset['sentiment'] = text_dataset['polarity'].apply(sentiment)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Preview the data frame\n",
    "text_dataset.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Visualize a distribution of data using count plot\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "sns.countplot(x='sentiment', data=text_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pie chart"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#visualize data in pie chart\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "colors = (\"yellowgreen\", \"gold\", \"red\")\n",
    "wp = {'linewidth': 2, 'edgecolor': \"black\"}\n",
    "tags = text_dataset['sentiment'].value_counts()\n",
    "explode = (0.1, 0.1, 0.1)\n",
    "tags.plot(kind='pie', autopct='%1.1f%%', shadow=True, colors=colors,\n",
    "          startangle=90, wedgeprops=wp, explode=explode, label='')\n",
    "plt.title('Distribution of sentiments')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#top 5 tweets in positive sentiment\n",
    "pos_tweets = text_dataset[text_dataset.sentiment == 'Positive']\n",
    "pos_tweets = pos_tweets.sort_values(['polarity'], ascending=False)\n",
    "pos_tweets.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Visualize all the positive tweets using word plot\n",
    "text = ' '.join([word for word in pos_tweets['text']])\n",
    "plt.figure(figsize=(20, 15), facecolor='None')\n",
    "wordcloud = WordCloud(max_words=500, width=1600, height=800).generate(text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Most frequent words in positive tweets', fontsize=19)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#top 5 tweets in negative sentiments\n",
    "neg_tweets = text_dataset[text_dataset.sentiment == 'Negative']\n",
    "neg_tweets = neg_tweets.sort_values(['polarity'], ascending=False)\n",
    "neg_tweets.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#visualize the negative tweets using word plot\n",
    "text = ' '.join([word for word in neg_tweets['text']])\n",
    "plt.figure(figsize=(20, 15), facecolor='None')\n",
    "wordcloud = WordCloud(max_words=500, width=1600, height=800).generate(text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Most frequent words in Negative tweets', fontsize=19)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#top 5 tweets in neutral sentiments\n",
    "neutral_tweets = text_dataset[text_dataset.sentiment == 'Neutral']\n",
    "neutral_tweets = neutral_tweets.sort_values(['polarity'], ascending=False)\n",
    "neutral_tweets.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#visualize the neutral tweets using word plot\n",
    "text = ' '.join([word for word utral_tweets['text']])\n",
    "plt.figure(figsize=(20, 15), facecolor='None')\n",
    "wordcloud = WordCloud(max_words=500, width=1600, height=800).generate(text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Most frequent words in Neutral tweets', fontsize=19)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#vectorize the data using count vectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#background language model\n",
    "vect = CountVectorizer(ngram_range=(1,2)).fit(text_dataset['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Display no of features and print 20 features\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\\n\".format(len(feature_names)))\n",
    "print(\"First 20 features:\\n {}\".format(feature_names[:20]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build the Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#seperate the data into x and y\n",
    "X = text_dataset['text']\n",
    "Y = text_dataset['sentiment']\n",
    "X = vect.transform(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#separate the data into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Size of x_train:\", (x_train.shape))\n",
    "print(\"Size of y_train:\", (y_train.shape))\n",
    "print(\"Size of x_test:\", (x_test.shape))\n",
    "print(\"Size of y_test:\", (y_test.shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ti ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train the data on logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "logreg_pred = logreg.predict(x_test)\n",
    "logreg_acc = accuracy_score(logreg_pred, y_test)\n",
    "print(\"Test accuracy: {:.2f}%\".format(logreg_acc*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confusion matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print(confusion_matrix(y_test, logreg_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, logreg_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "style.use('classic')\n",
    "cm = confusion_matrix(y_test, logreg_pred, labels=logreg.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels=logreg.classes_)\n",
    "disp.plot()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#perform hyper parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid={'C':[0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid)\n",
    "grid.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print the values for the given excess\n",
    "y_pred = grid.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#calculate the model accuracy\n",
    "logreg_acc = accuracy_score(y_pred, y_test)\n",
    "print(\"Test accuracy: {:.2f}%\".format(logreg_acc*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#updated confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#run the model on support vector machine\n",
    "#import support vector classifier\n",
    "from sklearn.svm import LinearSVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SVCmodel = LinearSVC()\n",
    "SVCmodel.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#split the data into test\n",
    "svc_pred = SVCmodel.predict(x_test)\n",
    "svc_acc = accuracy_score(svc_pred, y_test)\n",
    "#calculate the accuracy\n",
    "print(\"test accuracy: {:.2f}%\".format(svc_acc*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, svc_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, svc_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#hyperparameter tuning for the svm model\n",
    "grid = {\n",
    "    'C':[0.01, 0.1, 1, 10],\n",
    "    'kernel':[\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n",
    "    'degree':[1,3,5,7],\n",
    "    'gamma':[0.01,1]\n",
    "}\n",
    "grid = GridSearchCV(SVCmodel, param_grid)\n",
    "grid.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Best parameter:\", grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = grid.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#calculate the model accuracy\n",
    "logreg_acc = accuracy_score(y_pred, y_test)\n",
    "print(\"Test accuracy: {:.2f}%\".format(logreg_acc*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
